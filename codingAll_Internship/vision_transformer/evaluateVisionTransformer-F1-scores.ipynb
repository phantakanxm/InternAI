{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28d3522",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0b68a",
   "metadata": {},
   "source": [
    "# Set the configuration for ViT structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bce378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# กำหนดค่าคงที่พื้นฐานสำหรับโครงสร้าง ViT\n",
    "IMAGE_SIZE = 224\n",
    "PATCH_SIZE = 16\n",
    "NUM_LAYERS = 8\n",
    "EMBED_DIM = 384\n",
    "MLP_DIM = 4 * EMBED_DIM\n",
    "NUM_HEADS = 8\n",
    "NUM_CLASSES = 1000 \n",
    "DROPOUT_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e2d33",
   "metadata": {},
   "source": [
    "# Vision Transformer from scracth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b896e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(Model):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6, name=\"norm1\")\n",
    "        self.mha = MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim // num_heads,\n",
    "            dropout=dropout_rate,\n",
    "            name=\"multi_head_attention\"\n",
    "        )\n",
    "        self.dropout_mha_output = Dropout(dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6, name=\"norm2\")\n",
    "        self.mlp = Sequential([\n",
    "            Dense(mlp_dim, activation='gelu', name=\"mlp_dense_1\"),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embed_dim, name=\"mlp_dense_2\"),\n",
    "            Dropout(dropout_rate)\n",
    "        ], name=\"mlp_block\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_norm1 = self.norm1(inputs)\n",
    "        attn_output = self.mha(query=x_norm1, value=x_norm1, key=x_norm1, training=training)\n",
    "        attn_output_dropped = self.dropout_mha_output(attn_output, training=training)\n",
    "        x_res1 = inputs + attn_output_dropped\n",
    "        x_norm2 = self.norm2(x_res1)\n",
    "        mlp_output = self.mlp(x_norm2, training=training)\n",
    "        x_res2 = x_res1 + mlp_output\n",
    "        return x_res2\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'mlp_dim': self.mlp_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class VisionTransformer(Model):\n",
    "    def __init__(self, image_size=IMAGE_SIZE, num_classes=NUM_CLASSES, patch_size=PATCH_SIZE, embed_dim=EMBED_DIM,\n",
    "                 num_heads=NUM_HEADS, num_layers=NUM_LAYERS, mlp_dim=MLP_DIM, dropout_rate=0.1, **kwargs):\n",
    "        super(VisionTransformer, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        self.cls_token = self.add_weight(name=\"cls_token\", shape=[1, 1, embed_dim], initializer=tf.keras.initializers.RandomNormal(stddev=0.02), trainable=True)\n",
    "        self.pos_embed = self.add_weight(name=\"position_embedding\", shape=[1, self.num_patches + 1, embed_dim], initializer=tf.keras.initializers.RandomNormal(stddev=0.02), trainable=True)\n",
    "        self.pos_dropout = Dropout(dropout_rate)\n",
    "        self.patch_embed = Conv2D(filters=embed_dim, kernel_size=patch_size, strides=patch_size, padding='valid', name=\"patch_embed\")\n",
    "        self.encoder_layers = [EncoderBlock(embed_dim, num_heads, mlp_dim, dropout_rate) for _ in range(num_layers)]\n",
    "        self.norm_head = LayerNormalization(epsilon=1e-6, name=\"head_norm\")\n",
    "        self.head = Dense(num_classes, activation='softmax', name=\"classification_head\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        x = self.patch_embed(inputs)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "        cls_tokens = tf.tile(self.cls_token, [batch_size, 1, 1])\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_dropout(x, training=training)\n",
    "        for encoder in self.encoder_layers:\n",
    "            x = encoder(x, training=training)\n",
    "        cls_token_output = x[:, 0]\n",
    "        cls_token_output = self.norm_head(cls_token_output, training=training)\n",
    "        logits = self.head(cls_token_output, training=training)\n",
    "        return logits\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'image_size': self.num_patches**0.5 * self.patch_size, # Reconstruct from num_patches\n",
    "            'num_classes': self.num_classes,\n",
    "            'patch_size': self.patch_size,\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'num_layers': self.num_layers,\n",
    "            'mlp_dim': self.mlp_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900eb6ba",
   "metadata": {},
   "source": [
    "# WarmupCosineDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626aed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, warmup_steps, alpha=0.0, name=None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.alpha = alpha\n",
    "        self.cosine_decay_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=self.initial_learning_rate,\n",
    "            decay_steps=self.decay_steps - self.warmup_steps,\n",
    "            alpha=self.alpha\n",
    "        )\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step_float = tf.cast(step, tf.float32)\n",
    "        warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)\n",
    "        def warmup_fn():\n",
    "            return (self.initial_learning_rate / warmup_steps_float) * step_float\n",
    "        def cosine_decay_fn():\n",
    "            return self.cosine_decay_schedule(step_float - warmup_steps_float)\n",
    "        learning_rate = tf.cond(step_float < warmup_steps_float, warmup_fn, cosine_decay_fn)\n",
    "        return learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_steps\": self.decay_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"alpha\": self.alpha,\n",
    "            \"name\": self.name\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87bdc57",
   "metadata": {},
   "source": [
    "# Predict a precision , recall and F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "\n",
    "# --- 1. กำหนดค่าและ Path ที่จำเป็น ---\n",
    "\n",
    "datapath = '/media/capybara/Data/dataset_vit/archive'\n",
    "best_model_path = '/media/capybara/Data/dataset_vit/codeVIT/best_vit_model_1000_classes.keras'\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "# --- 2. โหลดโมเดลและชุดข้อมูล Validation ---\n",
    "\n",
    "print(f\"กำลังโหลดโมเดล ViT จาก: {best_model_path}\")\n",
    "if not os.path.exists(best_model_path):\n",
    "    raise FileNotFoundError(f\"ไม่พบไฟล์โมเดลที่ '{best_model_path}'. กรุณาตรวจสอบ Path ให้ถูกต้อง\")\n",
    "\n",
    "# เพิ่ม custom_objects ตอนโหลดโมเดล\n",
    "model = tf.keras.models.load_model(\n",
    "    best_model_path,\n",
    "    custom_objects={\n",
    "        \"VisionTransformer\": VisionTransformer,\n",
    "        \"EncoderBlock\": EncoderBlock,\n",
    "        \"WarmupCosineDecay\": WarmupCosineDecay\n",
    "    }\n",
    ")\n",
    "print(\"โหลดโมเดลสำเร็จ\")\n",
    "\n",
    "print(f\"กำลังโหลดชุดข้อมูล Validation จาก: {datapath}\")\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    datapath,\n",
    "    validation_split=0.04,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = val_dataset.class_names\n",
    "print(f\"พบ {len(class_names)} คลาส\")\n",
    "\n",
    "def preprocess_val_data(images, labels):\n",
    "    images = images / 255.0  \n",
    "    return images, labels\n",
    "\n",
    "val_pipeline = val_dataset.map(preprocess_val_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_pipeline = val_pipeline.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# --- 3. ทำนายผล (Predict) และรวบรวมผลลัพธ์ ---\n",
    "y_pred = []\n",
    "y_true = []\n",
    "iteration = 0\n",
    "total_batches = len(val_pipeline)\n",
    "\n",
    "print(f\"\\nกำลังทำนายผลจากข้อมูล Validation ทั้งหมด {total_batches} batches...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for images, labels in val_pipeline:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(labels.numpy(), axis=1)\n",
    "    y_pred.extend(predicted_classes)\n",
    "    y_true.extend(true_classes)\n",
    "    \n",
    "    iteration += 1\n",
    "    if iteration % 50 == 0:\n",
    "        print(f\"  Processed {iteration}/{total_batches} batches...\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"ทำนายผลเสร็จสิ้นใน {end_time - start_time:.2f} วินาที\")\n",
    "\n",
    "# --- 4. คำนวณและแสดงผลลัพธ์ ---\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"            ผลการประเมินโมเดล (Classification Report)          \")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "present_labels = np.unique(y_true)\n",
    "print(f\"พบข้อมูลจริง {len(present_labels)} คลาสในชุด Validation ที่ใช้ประเมินผล\")\n",
    "\n",
    "present_class_names = [class_names[i] for i in present_labels]\n",
    "\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    labels=present_labels, \n",
    "    target_names=present_class_names,\n",
    "    zero_division=0,\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "print(\"\\n--- สรุปค่าเฉลี่ยประสิทธิภาพโมเดล ---\")\n",
    "report_dict = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "print(\"\\n[ แนะนำ ] ค่าเฉลี่ยแบบถ่วงน้ำหนัก (Weighted Average)\")\n",
    "print(f\"  - Precision: {report_dict['weighted avg']['precision']:.4f}\")\n",
    "print(f\"  - Recall:    {report_dict['weighted avg']['recall']:.4f}\")\n",
    "print(f\"  - F1-Score:  {report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(\"\\nค่าเฉลี่ยแบบไม่ถ่วงน้ำหนัก (Macro Average)\")\n",
    "print(f\"  - Precision: {report_dict['macro avg']['precision']:.4f}\")\n",
    "print(f\"  - Recall:    {report_dict['macro avg']['recall']:.4f}\")\n",
    "print(f\"  - F1-Score:  {report_dict['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(\"\\nความแม่นยำโดยรวม (Overall Accuracy)\")\n",
    "print(f\"  - Accuracy: {report_dict['accuracy']:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
